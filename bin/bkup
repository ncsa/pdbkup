#!/bin/bash

[[ -z "$PDBKUP_BASE" ]] && exit 1

DEBUG=0     #debug messages
VERBOSE=0   #info messages
while getopts ":dvf" opt; do
    case $opt in
    d) DEBUG=1; VERBOSE=1;;
    v) VERBOSE=1;;
    f) export PDBKUP_TYPE=FULL;;
    esac
done
shift $((OPTIND-1))

export BKUP_DEBUG=$DEBUG
export BKUP_VERBOSE=$VERBOSE

source $PDBKUP_BASE/lib/funcs.sh
source $PDBKUP_BASE/lib/read_ini.sh

read_ini $PDBKUP_BASE/conf/settings.ini
dirkeys=( $( get_all_vars_matching_prefix INI__DIRS__ 1 ) )

function all_bkup_dirs() {
    for d in "${dirkeys[@]}"; do
        dirpath="$INI__GENERAL__INFODIR/$d"
        [[ -d $dirpath ]] || continue
        find "$INI__GENERAL__INFODIR/$d" -mindepth 1 -maxdepth 1 -type d | sort
    done
}


function latest_bkupdir() {
    for d in "${dirkeys[@]}"; do
        find "$INI__GENERAL__INFODIR/$d" -mindepth 1 -maxdepth 1 -type d
    done \
    | sort -r \
    | head -1
}


function sanitize() {
    [[ $# -lt 1 ]] && die "sanitize: Missing bkupdir path"
    local infodir=$( readlink -e "$1" )
    [[ -n "$infodir" ]] || die "No such file or directory: '$1'. Parameter must be an infodir"
    [[ -d "$infodir" ]] || die "Not a directory '$infodir'. Parameter must be an infodir"
    local -a parts=( $( echo $infodir | bkupinfodir2key_ts ) )
    local key=${parts[0]}
    local ts=${parts[1]}
    [[ -n "$key" ]] || die "Error getting dirkey from infodir"
    [[ -n "$ts" ]] || die "Error getting timestamp from infodir"
    set -x
    find "$INI__GENERAL__DATADIR" -name "*${key}*${ts}*" -delete
    find "$infodir" -type f ! -name 'allfileslist.????' -delete
    set +x
}


function archive_status() {
    # Input: String - full path to bkupinfo dir
    # Output: String - IN-PROGRESS, COMPLETE, FAILURES-DETECTED
    [[ $DEBUG -gt 0 ]] && set -x
    [[ $# -lt 1 ]] && die "archive_status: Missing bkupdir path"
    local infodir="$1"
    local archive_status=UNKNOWN
    local key timestamp
    read key timestamp <<<$( echo "$infodir" | bkupinfodir2key_ts )
    # Check for unstarted or in progress DARs
    local dar_count=$( find $infodir -name "${key}*.dcf" | wc -l )
    local completed_count=$( find $infodir -name "${key}*.ini" | parallel grep EXITCODE {} | wc -l )
    # Check for dar errors
    local awktmp=$( mktemp )
    echo '/^EXITCODE/ && /[1-9]/ {print}' > $awktmp
    local error_count=$( find $infodir -name "${key}*.ini" \
    | parallel awk -f $awktmp \
    | wc -l )
    rm -f $awktmp
    if [[ $dar_count -lt 1 ]]; then
        archive_status=EMPTY
    elif [[ $completed_count -lt $dar_count ]]; then
        archive_status=IN-PROGRESS
    elif [[ $error_count -gt 0 ]]; then
        archive_status=FAILURES-DETECTED
    elif [[ $completed_count -eq $dar_count ]]; then
        archive_status=COMPLETE
    fi
    echo $archive_status
}


function transfer_status() {
    # Input: String - full path to bkupinfo dir
    # Output: String - IN-PROGRESS, COMPLETE, FAILURES-DETECTED
    [[ $DEBUG -gt 0 ]] && set -x
    [[ $# -lt 1 ]] && die "transfer_status: Missing bkupdir path"
    local infodir="$1"
    local tstatus=UNKNOWN
    local key timestamp
    read key timestamp <<<$( echo "$infodir" | bkupinfodir2key_ts )
    # Check for files being transfered
    local ready_dir="$INI__GENERAL__DATADIR/$INI__TXFR__SRCDIR_OUTBOUND"
    local work_dir="$INI__GENERAL__DATADIR/$INI__TXFR__WORKDIR_OUTBOUND"
    local err_dir="$INI__GENERAL__DATADIR/$INI__TXFR__ERRDIR_OUTBOUND"
    local ready_count=$( find "$ready_dir" -name "${key}_${timestamp}*" | wc -l )
    local working_count=$( find "$work_dir" -name "${key}_${timestamp}*" | wc -l )
    local err_count=$( find "$err_dir" -name "${key}_${timestamp}*" | wc -l )
    if [[ $err_count -gt 0 ]]; then
        tstatus=FAILURES-DETECTED
    elif [[ $working_count -gt 0 ]]; then
        tstatus=IN-PROGRESS
    elif [[ $ready_count -gt 0 ]]; then
        tstatus=PENDING
    else 
        local go_tgtdir="${INI__GLOBUS__ENDPOINT_REMOTE}:$INI__GLOBUS__BASEDIR_REMOTE/$key/$timestamp"
        local info_fn="${key}_${timestamp}_INFO.1.dar"
        local fcount=$( $INI__GLOBUS__CLI ls "$go_tgtdir" 2>/dev/null \
        | grep "$info_fn" \
        | wc -l )
        [[ $fcount -eq 1 ]] && tstatus=COMPLETE
    fi
    echo "$tstatus"
}


function do_ls_with_status() {
    # List all backups by date and key including bkup snapdate and status
    # Input: NONE
    # Output: Column formatted output
    [[ $DEBUG -gt 0 ]] && set -x
    (   echo "BKUP_DIR DATE TIME TYPE STATUS"
        all_bkup_dirs \
        | sort -t '/' -k 7 \
        | while read; do
            # infodir
            local infodir="$REPLY"
            debug "do_ls_with_status: checking '$infodir'"
            # timestamp
            local key timestamp
            read key timestamp <<< $( echo "$infodir" | bkupinfodir2key_ts )
            # snapshot date and time
            local sdate stime
            read sdate stime <<< $( timestamp2datetime $timestamp )
            # bkup type
            local bkup_type='FULL?'
            local all_fn=$( find "$infodir" -type f -name 'allfileslist.*' | head -1 )
            local btype="${all_fn##*.}"
            [[ -n "$btype" ]] && bkup_type="$btype"
            # status
            local status_file="$infodir/last_status"
            local last_status=UNKNOWN
            [[ -f "$status_file" ]] && last_status=$( head -1 "$status_file" )
            debug "do_ls_with_status: last_status = '$infodir'"
            local bkup_status="$last_status"
            if [[ "$bkup_status" == *'FAIL'* ]]; then
                debug "do_ls_with_status: bkup status '$bkup_status' matches FAIL, doing nothing"
            elif [[ "$bkup_status" != 'COMPLETE' ]]; then
                local arch_status txfr_status
                arch_status=$( archive_status "$infodir" )
                bkup_status="ARCHIVE($arch_status)"
                if [[ $arch_status == COMPLETE ]]; then
                    txfr_status=$( transfer_status "$infodir" )
                    bkup_status="TRANSFER($txfr_status)"
                    if [[ $txfr_status == COMPLETE ]]; then
                        bkup_status=COMPLETE
                    fi
                fi
                echo "$bkup_status" > "$status_file"
            fi
            echo "$infodir $sdate $stime $bkup_type $bkup_status"
        done
    ) | column -t
}


function dbstatus() {
    [[ $# -lt 1 ]] && die "Missing bkupdir path"
    local parts=( $( bkupinfodir2key_ts <<< "$1" ) )
    local workdir="$INI__GENERAL__DATADIR/$INI__PARALLEL__WORKDIR"
    local pfx="${parts[0]}_${parts[1]}"
    local cmdfile="$workdir/${pfx}.sqlworker.cmd"
    [[ -f "$cmdfile" ]] || clean_exit "Backup already completed"
    local dburl=$( dburl_from_sqlworkercmdfile "$cmdfile" )
    echo "HOSTS and JOB STATUS COUNT"
    sql -p '-column' "$dburl" "select Host,Exitval,count(*) from tasks group by Host,Exitval;"
    echo
    local num_ready=$( num_ready_tasks "$dburl" )
    local num_active=$( num_active_tasks "$dburl" )
    local num_done=$( num_successful_tasks "$dburl" )
    local num_failed=$( num_failed_tasks "$dburl" )
    local num_total
    let "num_total = $num_ready + $num_active + $num_done + $num_failed"
    local pct_ready=$( bc <<< "scale=2; $num_ready/$num_total * 100" )
    local pct_active=$( bc <<< "scale=2; $num_active/$num_total * 100" )
    local pct_done=$( bc <<< "scale=2; $num_done/$num_total * 100" )
    local pct_failed=$( bc <<< "scale=2; $num_failed/$num_total * 100" )
    printf "%10s: %5d  (%4.2f%%)\n" 'Failed' $num_failed $pct_failed
    printf "%10s: %5d  (%4.2f%%)\n" 'Successful' $num_done $pct_done
    printf "%10s: %5d  (%4.2f%%)\n" 'Active' $num_active $pct_active
    printf "%10s: %5d  (%4.2f%%)\n" 'Pending' $num_ready $pct_ready
    printf "%10s: %5d\n"       'Total' $num_total
}


function wrapup() {
    ###
    # For Completed Bkups
    #   - cleanup sqlworker cmd and task queue files
    #   - make archive of infodir
    ###
    ls_sqlworker_cmdfiles \
    | while read sqlcmd_fn; do
        # Get DBURL
        dburl=$( dburl_from_sqlworkercmdfile "$sqlcmd_fn" )
        debug "Found dburl '$dburl'"
        ready_count=$( num_ready_tasks "$dburl" )
        active_count=$( num_active_tasks "$dburl" )
        failed_count=$( num_failed_tasks "$dburl" )
        # If all tasks have completed
        if [[ $ready_count == 0 && $active_count == 0 ]] ; then
            debug "All tasks have completed"
            # If all tasks successful
            if [[ $failed_count -eq 0 ]]; then
                debug "No failed tasks (all successful)"
                # Determine key & timestamp
                read key ts <<< $(filename2key_ts "$sqlcmd_fn" )
                infodir="${INI__GENERAL__INFODIR}/${key}/${ts}"
                # Move sqlworker file to relevant INFODIR
                mv "$sqlcmd_fn" "$infodir"
                # Move DB file to relevant INFODIR
                dbfn=$( dburl2filename "$dburl" )
                mv "$dbfn" "$infodir"
                # Create archive of infodir to be shipped to Long Term Storage
                errmsg="Error finalizing archive of infodir '$infodir'."
                errmsg="$errmsg See '$infodir/wrapup.err' for more details."
                mk_infodir_bkup $infodir || die "$errmsg"
            else
                warn "Failures reported in WORKER QUEUE \"$dburl\""
            fi
        fi
    done
}


function mk_infodir_bkup() {
    ###
    # Make a dar backup archive of entire infodir and move to "ready_for_transfer" directory
    # INPUT
    #   - infodir - String - absolute path to infodir
    ###
    [[ $# -lt 1 ]] && die "Missing infodir path"
    local infodir=$1
    [[ -d $infodir ]] || die "Infodir path '$infodir' is not a directory"
    local key ts
    read key ts <<< $( bkupinfodir2key_ts <<< "$infodir" )
    local darbasename="${key}_${ts}_INFO"
    local darout="${INI__GENERAL__DATADIR}/${INI__DAR__WORKDIR}/$darbasename"
    local darfn="${darout}.1.dar"
    # Create dar archive
    local logfile="$infodir/wrapup.log"
    local errfile="$infodir/wrapup.err"
    log "Creating dar archive: '$darbasename' ..."
    local starttime=$SECONDS
    local exitcode
    ${INI__DAR__CMD} -Q -z -va \
        -c "$darout" \
        -R "$infodir" \
        -X 'wrapup.*' \
        1>"$logfile" \
        2>"$errfile"
    exitcode=$?
    local endtime=$SECONDS
    local elapsed=$( bc <<< "$endtime - $starttime" )
    log "Elapsed seconds: $elapsed"
    # Check dar success and move archive as appropriate
    local enddir="${INI__GENERAL__DATADIR}/${INI__DAR__ENDDIR}"
    if [[ $exitcode -ne 0 ]]; then
        enddir="${INI__GENERAL__DATADIR}/${INI__DAR__ERRDIR}"
        warn "dar exited with non-zero exitcode '$exitcode'"
    fi
    mv "$darfn" "$enddir/"
    return $exitcode
}


function usage() {
    cat <<ENDHERE

Usage: $1 [OPTIONS] <CMD>

  where OPTIONS is any of:
    -v   verbose
    -d   debug (implies verbose as well)
    -f   force a full backup (otherwise, first bkup is a full, rest are incremental)

  where CMD is one of:
    init        - initialize backups for the newest snapshot
                  OPTIONAL PARAMETER(s): DIRKEY1 [DIRKEY2 ...]
                  OPTIONAL PARAMETER: /path/to/existing/backup/infodir
                  DEFAULT: use latest snapshot
    startworker - start processing parallel jobs on a worker
    status      - report on a specific backup
                  OPTIONAL PARAMETER: /path/to/existing/backup/infodir
                  DEFAULT: use latest backup infodir
    dbstatus    - Display progress of parallel tasks
                  REQUIRED PARAMETER: /path/to/existing/backup/infodir
    wrapup      - Make dar of infodir and set it to move to long term storage
    ls          - list all known backups
    ps          - list all backup processes on the local node
    files       - list all files associated with a given backup
                  OPTIONAL PARAMETER: /path/to/existing/backup/infodir
                  DEFAULT: use latest backup infodir
    tree        - List file counts in dir tree rooted at "$INI__GENERAL__DATADIR"
    plotdar     - Create gnuplot of dar slice creation times vs filesiszes
    purge       - Purge all files from old, completed processes (includes txfrs)
    stop        - Stop the parallel process (allow subprocesses to complete)
    kill        - Stop ALL backup processes
    sanitize    - *caution* delete all files from specified backup
                  (use to allow init to rerun on a dir without re-scanning filesystem)
                  REQUIRED PARAMETER: /path/to/existing/backup/infodir
    reset       - *caution* delete entire backup tree

ENDHERE

}


action=$1
shift
logger -t pdbkup "bkup $action"
case $action in
    init) 
        set -x
        $PDBKUP_BASE/bin/mk_bkup_tasks $*
        set +x
        ;;
    startworker)
        exec $PDBKUP_BASE/bin/startworker
        ;;
    sanitize) 
        sanitize $*
        ;;
    reset) 
        read -p "Delete ALL under $INI__GENERAL__DATADIR and $INI__GENERAL__INFODIR trees? "
        if [[ "$REPLY" == "Y" ]]; then
            set -x
            find "$INI__GENERAL__DATADIR" -mindepth 1 -delete
            find "$INI__GENERAL__INFODIR" -mindepth 1 -delete
            set +x
        else
            die "Declined, exiting without making changes."
        fi
        ;;
    summary)
        d=$1
        [[ $# -lt 1 ]] && d=$( latest_bkupdir )
        exec $PDBKUP_BASE/bin/summary.py -j -s $d
        ;;
    dbstatus)
        dbstatus $*
        ;;
    wrapup)
        wrapup
        ;;
    errshow)
        warn "ERRSHOW NOT IMPLEMENTED YET"
        # Find errors in joblogs
        # Find errors in dar err files
        ;;
    ls) 
        do_ls_with_status
        ;;
    ps)
        psopts=( -o pid,stat,time,command --sort stat  )
        pgrep -f dar | xargs -r ps "${psopts[@]}" 
        pgrep -f parallel | xargs -r ps "${psopts[@]}"
        ;;
    files)
        d=$1
        [[ $# -lt 1 ]] && d=$( latest_bkupdir )
        parts=( $( bkupinfodir2key_ts <<< "$d" ) )
        find "${INI__GENERAL__DATADIR}" -name "*${parts[1]}*"
        find "${INI__GENERAL__INFODIR}" -name "*${parts[1]}*"
        ;;
    tree)
        find "$INI__GENERAL__DATADIR" -maxdepth 1 -mindepth 1 -type d \
        | sort \
        | while read; do
            count=$( ls "$REPLY" | wc -l )
            printf "%3d  %s\n" $count $REPLY
        done
        ;;
    purge)
        find "${INI__GENERAL__DATADIR}/${INI__PURGE__SRCDIR}" -mindepth 1 -delete
        ;;
    stop)
        touch $( gatekeeper_fn )
        pkill -f parallel
        ;;
    kill)
        touch $( gatekeeper_fn )
        pkill -f parallel
        pkill -f dar
        ;;
    plot*)
        d=$1
        [[ $# -lt 1 ]] && d=$( latest_bkupdir )
        exec $PDBKUP_BASE/bin/$action $d
        ;;
    ini)
        export BKUP_DEBUG=1
        export BKUP_VERBOSE=1
        dump_ini
        ;;
#    qls)
#        next_worker_cmdfile
#        ;;
#    qnext)
#        next_worker_cmdfile
#        ;;
    *)
        usage $(basename "$0")
        ;;
esac
